{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c92e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Étape 1 : Charger le dataset\n",
    "file_path = r\"dataset.csv\"  # Mettez ici le chemin correct de votre fichier CSV\n",
    "try:\n",
    "    dataset = pd.read_csv(file_path)\n",
    "    print(\"Dataset chargé avec succès !\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"Le fichier spécifié n'existe pas à l'emplacement : {file_path}\")\n",
    "\n",
    "# Étape 2 : Afficher les colonnes du dataset pour identifier la colonne cible\n",
    "print(\"\\nColonnes disponibles dans le dataset :\")\n",
    "print(dataset.columns)\n",
    "\n",
    "# Demander à l'utilisateur de saisir le nom exact de la colonne cible\n",
    "target_column = input(\"\\nEntrez le nom exact de la colonne cible (par exemple 'popularity') : \")\n",
    "# Vérifier si la colonne cible existe\n",
    "if target_column not in dataset.columns:\n",
    "    raise ValueError(f\"La colonne cible '{target_column}' n'existe pas dans le dataset. Veuillez vérifier.\")\n",
    "\n",
    "\n",
    "# Étape 3 : Aperçu des données\n",
    "print(\"\\nAperçu des premières lignes du dataset :\")\n",
    "print(dataset.head())\n",
    "print(\"\\nInformations sur le dataset :\")\n",
    "print(dataset.info())\n",
    "\n",
    "# Étape 4 : Vérification des valeurs manquantes\n",
    "missing_values = dataset.isnull().sum()\n",
    "print(\"\\nValeurs manquantes par colonne :\")\n",
    "print(missing_values)\n",
    "\n",
    "# Étape 5 : Traitement des colonnes non numériques et valeurs manquantes\n",
    "# Identifier les colonnes non numériques\n",
    "non_numeric_columns = dataset.select_dtypes(include=['object']).columns\n",
    "if len(non_numeric_columns) > 0:\n",
    "    print(\"\\nColonnes non numériques détectées :\", list(non_numeric_columns))\n",
    "    # Remplir les colonnes non numériques avec une valeur par défaut (exemple : \"Inconnu\")\n",
    "    dataset[non_numeric_columns] = dataset[non_numeric_columns].fillna(\"Inconnu\")\n",
    "\n",
    "\n",
    "# Remplir les colonnes numériques avec leur moyenne\n",
    "numeric_columns = dataset.select_dtypes(include=['float64', 'int64']).columns\n",
    "if len(numeric_columns) > 0:\n",
    "    dataset[numeric_columns] = dataset[numeric_columns].fillna(dataset[numeric_columns].mean())\n",
    "\n",
    "print(\"\\nValeurs manquantes traitées.\")\n",
    "\n",
    "# **Étape 6 : Statistiques Descriptives**\n",
    "print(\"\\nStatistiques descriptives :\")\n",
    "print(dataset[numeric_columns].describe())\n",
    "\n",
    "# Supprimer la colonne 'Unnamed: 0' si elle est présente\n",
    "dataset = dataset.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "\n",
    "\n",
    "# Séparer les features (X) et la target (y)\n",
    "X = dataset.drop(columns=[target_column])\n",
    "y = dataset[target_column]\n",
    "\n",
    "\n",
    "\n",
    "# Sélectionner uniquement les colonnes numériques pour X\n",
    "X_numeric = X.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "\n",
    "\n",
    "# Étape 7 : Normalisation des données\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_numeric)  # Normaliser uniquement les colonnes numériques\n",
    "\n",
    "\n",
    "# Étape 8 : Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Étape 9 : Résumé des ensembles\n",
    "print(\"\\nTaille de l'ensemble d'entraînement :\", X_train.shape)\n",
    "print(\"Taille de l'ensemble de test :\", X_test.shape)\n",
    "print(\"\\nPréparation des données terminée avec succès !\")\n",
    "\n",
    "\n",
    "# 1. Analyse de la corrélation (en excluant les colonnes non numériques)\n",
    "numeric_data = dataset.select_dtypes(include=['float64', 'int64'])  # Ne conserver que les colonnes numériques\n",
    "correlation_matrix = numeric_data.corr()\n",
    "\n",
    "\n",
    "# Afficher la matrice de corrélation avec un heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Matrice de Corrélation\")\n",
    "plt.show()\n",
    "\n",
    "# Afficher la corrélation de chaque feature avec la target\n",
    "correlation_with_target = correlation_matrix[target_column].sort_values(ascending=False)\n",
    "print(\"\\nCorrélation avec la variable cible :\")\n",
    "print(correlation_with_target)\n",
    "\n",
    "# 2. Sélection de K meilleures features avec SelectKBest\n",
    "# Appliquer l'imputation et sélectionner les K meilleures caractéristiques\n",
    "imputer = SimpleImputer(strategy='mean')  # Imputer les valeurs manquantes par la moyenne\n",
    "X_imputed = imputer.fit_transform(X_numeric)  # Imputer les colonnes numériques\n",
    "\n",
    "\n",
    "# Sélectionner les K meilleures features (par exemple, les 5 meilleures)\n",
    "selector = SelectKBest(score_func=f_regression, k=5)  # Sélectionner les 5 meilleures features\n",
    "X_new = selector.fit_transform(X_imputed, y)\n",
    "\n",
    "\n",
    "# Vous pouvez ensuite accéder aux indices des meilleures caractéristiques :\n",
    "selected_columns = X_numeric.columns[selector.get_support()]\n",
    "print(\"Les meilleures caractéristiques sélectionnées : \", selected_columns)\n",
    "\n",
    "\n",
    "#Créer des features supplémentaires\n",
    "# Calcul de la popularité moyenne par genre\n",
    "genre_popularity = dataset.groupby('track_genre')['popularity'].mean()\n",
    "\n",
    "# Ajout de la popularité pondérée par genre à la dataset\n",
    "dataset['popularity_weighted_by_genre'] = dataset['track_genre'].map(genre_popularity)\n",
    "\n",
    "\n",
    "# Calcul du rapport énergie/danceabilité\n",
    "dataset['energy_to_danceability_ratio'] = dataset['energy'] / dataset['danceability']\n",
    "\n",
    "\n",
    "# Conversion de la durée de millisecondes à minutes\n",
    "dataset['duration_normalized'] = dataset['duration_ms'] / 60000  # 1 minute = 60000 millisecondes\n",
    "\n",
    "\n",
    "# Initialiser le modèle de régression linéaire\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Entraîner le modèle avec l'ensemble d'entraînement\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Calculer les métriques de performance\n",
    "initial_mse = mean_squared_error(y_test, y_pred)\n",
    "initial_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n=== Résultats du Modèle Initial ===\")\n",
    "print(f\"Erreur Quadratique Moyenne (MSE) : {initial_mse:.2f}\")\n",
    "print(f\"Score R² : {initial_r2:.2f}\")\n",
    "\n",
    "\n",
    "# Exemple d'utilisation de GridSearchCV pour vérifier si normaliser les données améliore les performances\n",
    "param_grid = {\n",
    "    'fit_intercept': [True, False],  # Inclure ou non l'intercept\n",
    "    # 'normalize': [True, False],  # Normalisation des données - This parameter is removed\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=LinearRegression(),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs hyperparamètres\n",
    "best_params = grid_search.best_params_\n",
    "print(\"\\n=== Meilleurs Hyperparamètres ===\")\n",
    "print(best_params)\n",
    "\n",
    "# Réentraîner le modèle avec les meilleurs paramètres\n",
    "lr_model_optimized = LinearRegression(**best_params)\n",
    "\n",
    "# Entraîner le modèle optimisé\n",
    "lr_model_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "y_pred_optimized = lr_model_optimized.predict(X_test)\n",
    "\n",
    "# Calculer les métriques\n",
    "optimized_mse = mean_squared_error(y_test, y_pred_optimized)\n",
    "optimized_r2 = r2_score(y_test, y_pred_optimized)\n",
    "\n",
    "print(\"\\n=== Résultats du Modèle Optimisé ===\")\n",
    "print(f\"Erreur Quadratique Moyenne (MSE) : {optimized_mse:.2f}\")\n",
    "print(f\"Score R² : {optimized_r2:.2f}\")\n",
    "\n",
    "\n",
    "# Visualisation des prédictions vs valeurs réelles\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_optimized, alpha=0.7, color='blue')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\n",
    "plt.title(\"Prédictions vs Valeurs Réelles (Modèle Optimisé)\")\n",
    "plt.xlabel(\"Valeurs Réelles\")\n",
    "plt.ylabel(\"Prédictions\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Distribution des résidus\n",
    "residuals = y_test - y_pred_optimized\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(residuals, bins=30, color='purple', alpha=0.7)\n",
    "plt.title(\"Distribution des Résidus\")\n",
    "plt.xlabel(\"Résidu\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Évaluation croisée\n",
    "from sklearn.model_selection import cross_val_score # Import the cross_val_score function\n",
    "\n",
    "cv_scores = cross_val_score(lr_model_optimized, X_train, y_train, cv=5, scoring='r2')\n",
    "print(\"Scores R² par pli de validation croisée : \", cv_scores)\n",
    "print(\"Score R² moyen : \", cv_scores.mean())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
